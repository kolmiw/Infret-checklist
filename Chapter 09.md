## a. Can you describe a very simple evaluation setup, in which pairs of (query, document) are associated with relevant/non-relevant flags?

## b. In the above setup, given a query, can you explain what precision is?

## c. In the above setup, given a query, can you explain what recall is?

## d. In the above setup, given a query, can you explain what accuracy is?

## e. In the above setup, given a query, can you explain what specificity is?

## f. Can you easily compute each of the above quantities given concrete numbers?

## g. Can you explain why accuracy is a poor evaluation measure and how it can very easily be "hacked"?

## h. Can you explain the precision vs. recall curve in the context of ranked retrieval?

## i. Can you tell when such a curve tells us the system has high quality, or poor quality?

## j. Can you explain what the ROC curve does? Do you know what it plots against what? Do you understand the analogy with metal detectors?
